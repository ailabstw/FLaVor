{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D segmentation task with FLaVor inference service"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide will walk you through tailoring the FLaVor inference service for 2D segmentation tasks using the model from [lungmask](https://github.com/JoHof/lungmask)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the working environment, please ensure you have the following dependencies installed:\n",
    "\n",
    "```\n",
    "python >= 3.10\n",
    "lungmask == 0.2.18\n",
    "numpy < 2.0.0\n",
    "```\n",
    "\n",
    "or simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry install --with seg_example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from lungmask import LMInferer\n",
    "\n",
    "from flavor.serve.apps import InferAPP\n",
    "from flavor.serve.inference.data_models.api import (\n",
    "    BaseAiCOCOImageInputDataModel,\n",
    "    BaseAiCOCOImageOutputDataModel,\n",
    ")\n",
    "from flavor.serve.inference.data_models.functional import AiImage\n",
    "from flavor.serve.inference.inference_models import BaseAiCOCOImageInferenceModel\n",
    "from flavor.serve.inference.strategies import AiCOCOSegmentationOutputStrategy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup inference model\n",
    "\n",
    "In this section, we would create `ClassificationInferenceModel` inheriting from `BaseAiCOCOImageInferenceModel`. There are few abstract methods that we must override such as `define_inference_network`, `set_categories`, `set_regressions`, `data_reader` and `output_formatter`. For the inference process related methods such as `preprocess`, `inference` and `postprocess`, we override them if necessary. `preprocess` and `postprocess` would remain an identical operation if unmodified. `inference` by default runs `self.forward(x)`.\n",
    "\n",
    "Firstly, we need to implement submethods: `define_inference_network`, `set_categories` and `set_regressions`. These are defined in the `__init__()` constructor of the parent class `BaseAiCOCOImageInferenceModel`. `define_inference_network` defines your inference network and loads its pre-trained weight. `set_categories` and `set_regressions` define category and regression information. For example, a segmentation output would contain `c` channels. We need to show the exact meaning of each channel by specifying in `set_categories`. Refer to the following example for more detail.\n",
    "\n",
    "Next, we implement other submethods that would be used in the `__call__` function of our inference model. See below workflow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `__call__` function workflow for the inference model\n",
    "![__call__](images/call.png \"inference workflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationInferenceModel(BaseAiCOCOImageInferenceModel):\n",
    "    def __init__(self):\n",
    "        self.formatter = AiCOCOSegmentationOutputStrategy()\n",
    "        super().__init__()\n",
    "\n",
    "    def define_inference_network(self) -> Callable:\n",
    "        return LMInferer(modelname=\"LTRCLobes\", fillmodel=\"R231\")\n",
    "\n",
    "    def set_categories(self) -> List[Dict[str, Any]]:\n",
    "        categories = [\n",
    "            {\"name\": \"Background\", \"display\": False},\n",
    "            {\"name\": \"Left Upper Lobe\", \"display\": True},\n",
    "            {\"name\": \"Left Lower Lobe\", \"display\": True},\n",
    "            {\"name\": \"Right Upper Lobe\", \"display\": True},\n",
    "            {\"name\": \"Right Middle Lobe\", \"display\": True},\n",
    "            {\"name\": \"Right Lower Lobe\", \"display\": True},\n",
    "        ]\n",
    "        return categories\n",
    "\n",
    "    def set_regressions(self) -> None:\n",
    "        return None\n",
    "\n",
    "    def data_reader(self, files: Sequence[str], **kwargs) -> Tuple[np.ndarray, None, None]:\n",
    "        dicom_reader = sitk.ImageFileReader()\n",
    "        dicom_reader.SetFileName(files[0])\n",
    "        dicom_reader.ReadImageInformation()\n",
    "        dicom = sitk.GetArrayFromImage(dicom_reader.Execute()).squeeze()\n",
    "\n",
    "        return dicom, None, None\n",
    "\n",
    "    def preprocess(self, data: np.ndarray) -> np.ndarray:\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "        return data\n",
    "\n",
    "    def inference(self, x: np.ndarray) -> np.ndarray:\n",
    "        return self.network.apply(x)\n",
    "\n",
    "    def postprocess(self, out: Any, metadata: Optional[Any] = None) -> np.ndarray:\n",
    "        # (1, h, w) -> (c, h, w)\n",
    "        out = [\n",
    "            np.expand_dims((out == i).astype(np.uint8), axis=0)\n",
    "            for i in range(6)  # or len(self.categories)\n",
    "        ]\n",
    "        out = np.concatenate(out, axis=0)\n",
    "        return out\n",
    "\n",
    "    def output_formatter(\n",
    "        self,\n",
    "        model_out: np.ndarray,\n",
    "        images: Sequence[AiImage],\n",
    "        categories: Sequence[Dict[str, Any]],\n",
    "        **kwargs\n",
    "    ) -> BaseAiCOCOImageOutputDataModel:\n",
    "\n",
    "        output = self.formatter(model_out=model_out, images=images, categories=categories)\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration with InferAPP\n",
    "We could integrate our defined inference model with FLaVor `InferAPP`, a FastAPI application. To initiate the application, users have to define `input_data_model` and `output_data_model` which are the standard input and output structure for the service. Then, provide `infer_function` as the main inference operation. After initiate the service, `/invocations` API end point would be available to process the inference request. We encourge users to implement a stand-alone python script based on this jupyter notebook tutorial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) to initiate application in jupyter notebook, you have to run the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is only for jupyter notebook. You don't need this in stand-alone script.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = InferAPP(\n",
    "    infer_function=SegmentationInferenceModel(),\n",
    "    input_data_model=BaseAiCOCOImageInputDataModel,\n",
    "    output_data_model=BaseAiCOCOImageOutputDataModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run(port=int(os.getenv(\"PORT\", 9111)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send request\n",
    "We can send request to the running server by `send_request.py` which opens the input files and the corresponding JSON file and would be sent via formdata. We expect to have response in AiCOCO format.\n",
    "\n",
    "```bash\n",
    "# pwd: examples/inference\n",
    "python send_request.py -f test_data/seg/0.dcm -d test_data/seg/input.json\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dockerfile\n",
    "In order to interact with other services, we have to wrap the inference model into a docker container. Here's an example of the dockerfile."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```dockerfile\n",
    "FROM nvidia/cuda:12.2.2-runtime-ubuntu20.04\n",
    "\n",
    "RUN apt-get update \\\n",
    "    && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\n",
    "        python3 \\\n",
    "        python3-pip \\\n",
    "    && ln -sf /usr/bin/python3 /usr/bin/python\n",
    "\n",
    "RUN pip install lungmask\n",
    "RUN pip install https://github.com/ailabstw/FLaVor/archive/refs/heads/release/stable.zip -U && pip install flavor\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY your_script.py  /app/\n",
    "\n",
    "CMD [\"python\", \"your_script.py\"]\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flavor-ObFXzz_m-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
