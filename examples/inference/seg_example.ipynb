{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D segmentation task with FLaVor inference service"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide will walk you through tailoring the FLaVor inference service for 2D segmentation tasks using the model from [lungmask](https://github.com/JoHof/lungmask)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the working environment, please ensure you have the following dependencies installed:\n",
    "\n",
    "```\n",
    "python > 3.8\n",
    "torch > 1.13\n",
    "lungmask == 0.2.18\n",
    "```\n",
    "\n",
    "or simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry install --with examples --extras infer "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from lungmask import LMInferer\n",
    "\n",
    "from flavor.serve.apps import InferAPP\n",
    "from flavor.serve.inference import (\n",
    "    BaseAiCOCOInferenceModel,\n",
    "    BaseAiCOCOInputDataModel,\n",
    "    BaseAiCOCOOutputDataModel,\n",
    ")\n",
    "from flavor.serve.models import AiImage, InferCategory\n",
    "from flavor.serve.strategies import AiCOCOSegmentationOutputStrategy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup inference model\n",
    "\n",
    "In this section, we would create `SegmentationInferenceModel` inheriting from `BaseAiCOCOInferenceModel`. There are few abstract methods that we must override such as `define_inference_network`, `set_categories`, `set_regressions`, `data_reader` and `output_formatter`. As for `preprocess`, `inference` and `postprocess`, it is optional but here we override them since we are executing a 3D model.\n",
    "\n",
    "Firstly, we need to implement submethods: `define_inference_network`, `set_categories` and `set_regressions`. These are defined in the `__init__()` constructor of the parent class `BaseAiCOCOInferenceModel`. `define_inference_network` defines your inference network and loads its pre-trained weight. `set_categories` and `set_regressions` define category and regression information. For example, a segmentation output would contain `c` channels. We need to show the exact meaning of each channel by specifying in `set_categories`. Refer to the following example for more detail.\n",
    "\n",
    "Next, we implement other submethods that would be used in the `__call__` function of our inference model. See below workflow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `__call__` function workflow for the inference model\n",
    "![__call__](images/call.png \"inference workflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationInferenceModel(BaseAiCOCOInferenceModel):\n",
    "    def __init__(self):\n",
    "        self.formatter = AiCOCOSegmentationOutputStrategy()\n",
    "        super().__init__()\n",
    "\n",
    "    def define_inference_network(self):\n",
    "        return LMInferer(modelname=\"LTRCLobes\", fillmodel=\"R231\")\n",
    "\n",
    "    def set_categories(self):\n",
    "        categories = [\n",
    "            {\"name\": \"Background\", \"display\": False},\n",
    "            {\"name\": \"Left Upper Lobe\", \"display\": True},\n",
    "            {\"name\": \"Left Lower Lobe\", \"display\": True},\n",
    "            {\"name\": \"Right Upper Lobe\", \"display\": True},\n",
    "            {\"name\": \"Right Middle Lobe\", \"display\": True},\n",
    "            {\"name\": \"Right Lower Lobe\", \"display\": True},\n",
    "        ]\n",
    "        return categories\n",
    "\n",
    "    def set_regressions(self):\n",
    "        return None\n",
    "\n",
    "    def data_reader(self, files: Sequence[str], **kwargs) -> Tuple[np.ndarray, None, None]:\n",
    "        dicom_reader = sitk.ImageFileReader()\n",
    "        dicom_reader.SetFileName(files[0])\n",
    "        dicom_reader.ReadImageInformation()\n",
    "        dicom = sitk.GetArrayFromImage(dicom_reader.Execute()).squeeze()\n",
    "\n",
    "        return dicom, None, None\n",
    "\n",
    "    def preprocess(self, data: np.ndarray) -> np.ndarray:\n",
    "        data = np.expand_dims(data, axis=0)\n",
    "        return data\n",
    "\n",
    "    def inference(self, x: np.ndarray) -> np.ndarray:\n",
    "        return self.network.apply(x)\n",
    "\n",
    "    def postprocess(self, out: Any, metadata: Any = None) -> Any:\n",
    "        # (1, h, w) -> (c, h, w)\n",
    "        out = [\n",
    "            np.expand_dims((out == i).astype(np.uint8), axis=0)\n",
    "            for i in range(6)  # or len(self.categories)\n",
    "        ]\n",
    "        out = np.concatenate(out, axis=0)\n",
    "        return out\n",
    "\n",
    "    def output_formatter(\n",
    "        self,\n",
    "        model_out: np.ndarray,\n",
    "        images: Sequence[AiImage],\n",
    "        categories: Sequence[InferCategory],\n",
    "        **kwargs\n",
    "    ) -> Any:\n",
    "\n",
    "        output = self.formatter(model_out=model_out, images=images, categories=categories)\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration with InferAPP\n",
    "We could integrate our defined inference model with FLaVor `InferAPP`, a FastAPI application. To initiate the application, users have to define `input_data_model` and `output_data_model` which are the standard input and output structure for the service. Then, provide `infer_function` as the main inference operation. After initiate the service, `/invocations` API end point would be available to process the inference request. We encourge users to implement a stand-alone python script based on this jupyter notebook tutorial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) to initiate application in jupyter notebook, you have to run the following block.\n",
    "\n",
    "```python\n",
    "# This block is only for jupyter notebook. You don't need this in stand-alone script.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = InferAPP(\n",
    "    infer_function=SegmentationInferenceModel(),\n",
    "    input_data_model=BaseAiCOCOInputDataModel,\n",
    "    output_data_model=BaseAiCOCOOutputDataModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run(port=int(os.getenv(\"PORT\", 9111)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send request\n",
    "We can send request to the running server by `send_request.py` which opens the input files and the coresponding JSON file and would be sent via formdata. We expect to have response in AiCOCO format.\n",
    "\n",
    "```bash\n",
    "# pwd: examples/inference\n",
    "python send_request.py -f test_data/seg/0.dcm -d test_data/seg/input.json\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dockerfile\n",
    "In order to interact with other services, we have to wrap the inference model into a docker container. Here's an example of the dockerfile."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```dockerfile\n",
    "FROM nvidia/cuda:12.2.2-runtime-ubuntu20.04\n",
    "\n",
    "RUN apt-get update \\\n",
    "    && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\n",
    "        python3.9 \\\n",
    "        python3-pip \\\n",
    "    && ln -sf /usr/bin/python3.9 /usr/bin/python\n",
    "    && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends wget\\\n",
    "\n",
    "RUN pip install torch==2.1.0+cu121 --extra-index-url https://download.pytorch.org/whl/cu121 --default-timeout=1000\n",
    "RUN pip install https://github.com/ailabstw/FLaVor/archive/refs/heads/release/stable.zip -U && pip install \"flavor[infer]\"\n",
    "RUN pip install monai==0.2.18\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY your_script.py  /app/\n",
    "\n",
    "CMD [\"python\", \"your_script.py\"]\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flavor-ObFXzz_m-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
