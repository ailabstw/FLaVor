{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D object detection task with FLaVor inference service"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide will walk you through tailoring the FLaVor inference service for 2D object detection tasks using the model from [YOLOv8-Medical-Imaging](https://github.com/sevdaimany/YOLOv8-Medical-Imaging)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the working environment, please ensure you have the following dependencies installed:\n",
    "\n",
    "```\n",
    "python >= 3.10\n",
    "ultralytics\n",
    "numpy < 2.0.0\n",
    "```\n",
    "\n",
    "or simply run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry install --with det_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, download pretrain weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd: examples/inference\n",
    "!wget https://github.com/sevdaimany/YOLOv8-Medical-Imaging/raw/master/runs/detect/train/weights/best.pt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Callable, Dict, List, Sequence, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from flavor.serve.apps import InferAPP\n",
    "from flavor.serve.inference.data_models.api import (\n",
    "    BaseAiCOCOImageInputDataModel,\n",
    "    BaseAiCOCOImageOutputDataModel,\n",
    ")\n",
    "from flavor.serve.inference.data_models.functional import AiImage\n",
    "from flavor.serve.inference.inference_models import BaseAiCOCOImageInferenceModel\n",
    "from flavor.serve.inference.strategies import AiCOCODetectionOutputStrategy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup inference model\n",
    "\n",
    "In this section, we would create `ClassificationInferenceModel` inheriting from `BaseAiCOCOImageInferenceModel`. There are few abstract methods that we must override such as `define_inference_network`, `set_categories`, `set_regressions`, `data_reader` and `output_formatter`. For the inference process related methods such as `preprocess`, `inference` and `postprocess`, we override them if necessary. `preprocess` and `postprocess` would remain an identical operation if unmodified. `inference` by default runs `self.forward(x)`.\n",
    "\n",
    "Firstly, we need to implement submethods: `define_inference_network`, `set_categories` and `set_regressions`. These are defined in the `__init__()` constructor of the parent class `BaseAiCOCOImageInferenceModel`. `define_inference_network` defines your inference network and loads its pre-trained weight. `set_categories` and `set_regressions` define category and regression information. For example, a classification output would contain `c` channels. We need to show the exact meaning of each channel by specifying in `set_categories`. Refer to the following example for more detail.\n",
    "\n",
    "Next, we implement other submethods that would be used in the `__call__` function of our inference model. See below workflow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `__call__` function workflow for the inference model\n",
    "![__call__](images/call.png \"inference workflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionInferenceModel(BaseAiCOCOImageInferenceModel):\n",
    "    def __init__(self):\n",
    "        self.formatter = AiCOCODetectionOutputStrategy()\n",
    "        super().__init__()\n",
    "\n",
    "    def define_inference_network(self) -> Callable:\n",
    "        ckpt_path = os.path.join(os.getcwd(), \"best.pt\")\n",
    "        if not os.path.exists(ckpt_path):\n",
    "            from urllib.request import urlretrieve\n",
    "\n",
    "            urlretrieve(\n",
    "                \"https://github.com/sevdaimany/YOLOv8-Medical-Imaging/raw/master/runs/detect/train/weights/best.pt\",\n",
    "                ckpt_path,\n",
    "            )\n",
    "        return YOLO(ckpt_path)\n",
    "\n",
    "    def set_categories(self) -> List[Dict[str, Any]]:\n",
    "        categories = [\n",
    "            {\"name\": \"RBC\", \"display\": True},\n",
    "            {\"name\": \"WBC\", \"display\": True},\n",
    "            {\"name\": \"Platelets\", \"display\": True},\n",
    "        ]\n",
    "        return categories\n",
    "\n",
    "    def set_regressions(self) -> None:\n",
    "        return None\n",
    "\n",
    "    def data_reader(self, files: Sequence[str], **kwargs) -> Tuple[np.ndarray, None, None]:\n",
    "        image = cv2.imread(files[0])\n",
    "        image = image.astype(np.float32)\n",
    "\n",
    "        return image, None, None\n",
    "\n",
    "    def inference(self, x: np.ndarray) -> Any:\n",
    "        return self.network.predict(x, conf=0.7)[0]\n",
    "\n",
    "    def postprocess(self, model_out: Any, **kwargs) -> Dict[str, Any]:\n",
    "\n",
    "        format_output = {\n",
    "            \"bbox_pred\": [],\n",
    "            \"cls_pred\": [],\n",
    "            \"confidence_score\": [],\n",
    "        }\n",
    "\n",
    "        for obj in model_out.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = obj\n",
    "            format_output[\"bbox_pred\"].append([int(x1), int(y1), int(x2), int(y2)])\n",
    "            cls_pred = np.zeros(3)\n",
    "            cls_pred[int(class_id)] = 1\n",
    "            format_output[\"cls_pred\"].append(cls_pred)\n",
    "            format_output[\"confidence_score\"].append(score)\n",
    "\n",
    "        return format_output\n",
    "\n",
    "    def output_formatter(\n",
    "        self,\n",
    "        model_out: Dict[str, Any],\n",
    "        images: Sequence[AiImage],\n",
    "        categories: Sequence[Dict[str, Any]],\n",
    "        regressions: Sequence[Dict[str, Any]],\n",
    "        **kwargs\n",
    "    ) -> BaseAiCOCOImageOutputDataModel:\n",
    "        output = self.formatter(\n",
    "            model_out=model_out, images=images, categories=categories, regressions=regressions\n",
    "        )\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration with InferAPP\n",
    "We could integrate our defined inference model with FLaVor `InferAPP`, a FastAPI application. To initiate the application, users have to define `input_data_model` and `output_data_model` which are the standard input and output structure for the service. Then, provide `infer_function` as the main inference operation. After initiate the service, `/invocations` API end point would be available to process the inference request. We encourge users to implement a stand-alone python script based on this jupyter notebook tutorial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) to initiate application in jupyter notebook, you have to run the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is only for jupyter notebook. You don't need this in stand-alone script.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = InferAPP(\n",
    "    infer_function=DetectionInferenceModel(),\n",
    "    input_data_model=BaseAiCOCOImageInputDataModel,\n",
    "    output_data_model=BaseAiCOCOImageOutputDataModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run(port=int(os.getenv(\"PORT\", 9111)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send request\n",
    "We can send request to the running server by `send_request.py` which opens the input files and the corresponding JSON file and would be sent via formdata. We expect to have response in AiCOCO format.\n",
    "\n",
    "```bash\n",
    "# pwd: examples/inference\n",
    "python send_request.py -f test_data/det/BloodImage_00000_jpg.rf.5fb00ac1228969a39cee7cd6678ee704.jpg -d test_data/det/input.json\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dockerfile\n",
    "In order to interact with other services, we have to wrap the inference model into a docker container. Here's an example of the dockerfile."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```dockerfile\n",
    "FROM nvidia/cuda:12.2.2-runtime-ubuntu20.04\n",
    "\n",
    "RUN apt-get update \\\n",
    "    && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\n",
    "        python3 \\\n",
    "        python3-pip \\\n",
    "    && ln -sf /usr/bin/python3 /usr/bin/python\n",
    "    && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends wget\\\n",
    "\n",
    "RUN pip install ultralytics\n",
    "RUN pip install https://github.com/ailabstw/FLaVor/archive/refs/heads/release/stable.zip -U && pip install flavor\n",
    "\n",
    "WORKDIR /app\n",
    "COPY your_script.py  /app/\n",
    "\n",
    "RUN wget https://github.com/sevdaimany/YOLOv8-Medical-Imaging/raw/master/runs/detect/train/weights/best.pt -P /app/\n",
    "\n",
    "CMD [\"python\", \"your_script.py\"]\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flavor-ObFXzz_m-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
