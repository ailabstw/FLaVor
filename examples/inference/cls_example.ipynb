{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D classification task with FLaVor inference service"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide will walk you through tailoring the FLaVor inference service for 2D classification tasks using ResNet18 inference model provided by `torchvision`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the working environment, please ensure you have the following dependencies installed:\n",
    "\n",
    "```\n",
    "python >= 3.10\n",
    "torch >= 1.13\n",
    "torchvision >= 0.14\n",
    "numpy < 2.0.0\n",
    "```\n",
    "\n",
    "or simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry install --with cls_example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, List, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "\n",
    "from flavor.serve.apps import InferAPP\n",
    "from flavor.serve.inference.data_models.api import (\n",
    "    BaseAiCOCOImageInputDataModel,\n",
    "    BaseAiCOCOImageOutputDataModel,\n",
    ")\n",
    "from flavor.serve.inference.data_models.functional import AiImage, InferCategory\n",
    "from flavor.serve.inference.inference_models import BaseAiCOCOImageInferenceModel\n",
    "from flavor.serve.inference.strategies import AiCOCOClassificationOutputStrategy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup inference model\n",
    "\n",
    "In this section, we would create `ClassificationInferenceModel` inheriting from `BaseAiCOCOImageInferenceModel`. There are few abstract methods that we must override such as `define_inference_network`, `set_categories`, `set_regressions`, `data_reader` and `output_formatter`. For the inference process related methods such as `preprocess`, `inference` and `postprocess`, we override them if necessary. `preprocess` and `postprocess` would remain an identical operation if unmodified. `inference` by default runs `self.forward(x)`.\n",
    "\n",
    "Firstly, we need to implement submethods: `define_inference_network`, `set_categories` and `set_regressions`. These are defined in the `__init__()` constructor of the parent class `BaseAiCOCOImageInferenceModel`. `define_inference_network` defines your inference network and loads its pre-trained weight. `set_categories` and `set_regressions` define category and regression information. For example, a classification output would contain `c` channels. We need to show the exact meaning of each channel by specifying in `set_categories`. Refer to the following example for more detail.\n",
    "\n",
    "Next, we implement other submethods that would be used in the `__call__` function of our inference model. See below workflow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `__call__` function workflow for the inference model\n",
    "![__call__](images/call.png \"inference workflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationInferenceModel(BaseAiCOCOImageInferenceModel):\n",
    "    def __init__(self):\n",
    "        self.formatter = AiCOCOClassificationOutputStrategy()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        super().__init__()\n",
    "\n",
    "    def define_inference_network(self):\n",
    "        network = resnet18(ResNet18_Weights.DEFAULT)\n",
    "        network.eval()\n",
    "        network.to(self.device)\n",
    "        return network\n",
    "    \n",
    "    def set_categories(self):\n",
    "        # ImageNet has 1000 categories\n",
    "        categories = [\n",
    "            {\"name\": str(i)} for i in range(1000)\n",
    "        ]\n",
    "        return categories\n",
    "\n",
    "    def set_regressions(self):\n",
    "        return None\n",
    "\n",
    "    def data_reader(self, files: Sequence[str], **kwargs) -> Tuple[np.ndarray, None, None]:\n",
    "        img = Image.open(files[0])\n",
    "        return img, None, None\n",
    "\n",
    "    def preprocess(self, data: np.ndarray) -> torch.Tensor:\n",
    "        transforms = ResNet18_Weights.DEFAULT.transforms()\n",
    "        img = transforms(data).unsqueeze(0).to(self.device)\n",
    "        return img\n",
    "    \n",
    "    def inference(self, x: Any) -> Any:\n",
    "        with torch.no_grad():\n",
    "            out = self.network(x)\n",
    "        return out\n",
    "\n",
    "    def postprocess(self, model_out: torch.Tensor, **kwargs) -> np.ndarray:\n",
    "        model_out = model_out.squeeze(0).cpu().detach()\n",
    "        model_out = (nn.functional.softmax(model_out, dim=0) > 0.4).long()\n",
    "        return model_out.numpy()\n",
    "\n",
    "    def output_formatter(\n",
    "        self,\n",
    "        model_out: np.ndarray,\n",
    "        images: Sequence[AiImage],\n",
    "        categories: List[InferCategory],\n",
    "        **kwargs\n",
    "    ) -> Any:\n",
    "\n",
    "        output = self.formatter(model_out=model_out, images=images, categories=categories)\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration with InferAPP\n",
    "We could integrate our defined inference model with FLaVor `InferAPP`, a FastAPI application. To initiate the application, users have to define `input_data_model` and `output_data_model` which are the standard input and output structure for the service. Then, provide `infer_function` as the main inference operation. After initiate the service, `/invocations` API end point would be available to process the inference request. We encourge users to implement a stand-alone python script based on this jupyter notebook tutorial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) to initiate application in jupyter notebook, you have to run the following block.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is only for jupyter notebook. You don't need this in stand-alone script.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = InferAPP(\n",
    "    infer_function=ClassificationInferenceModel(),\n",
    "    input_data_model=BaseAiCOCOImageInputDataModel,\n",
    "    output_data_model=BaseAiCOCOImageOutputDataModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run(port=int(os.getenv(\"PORT\", 9111)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send request\n",
    "We can send request to the running server by `send_request.py` which opens the input files and the corresponding JSON file and would be sent via formdata. We expect to have response in AiCOCO format.\n",
    "\n",
    "```bash\n",
    "# pwd: examples/inference\n",
    "python send_request.py -f test_data/cls_reg/n02123159_tiger_cat.jpeg -d test_data/cls_reg/input.json\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dockerfile\n",
    "In order to interact with other services, we have to wrap the inference model into a docker container. Here's an example of the dockerfile."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```dockerfile\n",
    "FROM nvidia/cuda:12.2.2-runtime-ubuntu20.04\n",
    "\n",
    "RUN apt-get update \\\n",
    "    && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\n",
    "        python3\\\n",
    "        python3-pip \\\n",
    "    && ln -sf /usr/bin/python3 /usr/bin/python\n",
    "\n",
    "RUN pip install torch==2.1.0+cu121 --extra-index-url https://download.pytorch.org/whl/cu121 --default-timeout=1000\n",
    "RUN pip install https://github.com/ailabstw/FLaVor/archive/refs/heads/release/stable.zip -U && pip install flavor\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY your_script.py  /app/\n",
    "\n",
    "CMD [\"python\", \"your_script.py\"]\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flavor-ObFXzz_m-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
