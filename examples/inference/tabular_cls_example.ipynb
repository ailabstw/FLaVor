{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular binary classification task with FLaVor inference service"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This guide will walk you through tailoring the FLaVor inference service for tabular binary classification tasks using seaborn dataset and sklearn inference model trained from `sklearn`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the working environment, please ensure you have the following dependencies installed:\n",
    "\n",
    "```\n",
    "python >= 3.9\n",
    "huggingface_hub >= 0.24.5\n",
    "```\n",
    "\n",
    "or simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry install --with tabular_cls_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from huggingface_hub import cached_download, hf_hub_url\n",
    "\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence\n",
    "\n",
    "from flavor.serve.apps import InferAPP\n",
    "from flavor.serve.inference.data_models.api import (\n",
    "    AiCOCOTabularInputDataModel,\n",
    "    AiCOCOTabularOutputDataModel,\n",
    ")\n",
    "from flavor.serve.inference.data_models.functional import AiTable\n",
    "from flavor.serve.inference.inference_models import BaseAiCOCOTabularInferenceModel\n",
    "from flavor.serve.inference.strategies import AiCOCOTabularClassificationOutputStrategy\n",
    "\n",
    "\n",
    "REPO_ID = \"julien-c/wine-quality\"\n",
    "FILENAME = \"sklearn_model.joblib\"\n",
    "\n",
    "\n",
    "class ClassificationInferenceModel(BaseAiCOCOTabularInferenceModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.formatter = AiCOCOTabularClassificationOutputStrategy()\n",
    "\n",
    "    def define_inference_network(self) -> Callable:\n",
    "        model = joblib.load(cached_download(hf_hub_url(REPO_ID, FILENAME)))\n",
    "        return model\n",
    "\n",
    "    def set_categories(self) -> List[Dict[str, Any]]:\n",
    "        categories = [{\"name\": str(grade)} for grade in range(3, 9)] # grade from 3 to 8\n",
    "        return categories\n",
    "\n",
    "    def set_regressions(self) -> None:\n",
    "        return None\n",
    "\n",
    "    def data_reader(self, tables: Dict[str, Any], files: Sequence[str], **kwargs) -> List[pd.DataFrame]:\n",
    "        table_names = [table[\"file_name\"].replace(\"/\", \"_\") for table in tables]\n",
    "\n",
    "        file_names = sorted(files, key=lambda s: s[::-1])\n",
    "        table_names = sorted(table_names, key=lambda s: s[::-1])\n",
    "        \n",
    "        dataframes = []\n",
    "        for file, table in zip(file_names, table_names):\n",
    "            if not file.endswith(table):\n",
    "                raise ValueError(f\"File names do not match table names: {file} vs {table}\")\n",
    "            \n",
    "            df = pd.read_csv(file)\n",
    "            dataframes.append(df)\n",
    "        \n",
    "        return dataframes\n",
    "\n",
    "    def preprocess(self, data: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "        return pd.concat(data)\n",
    "\n",
    "    def inference(self, x: pd.DataFrame):\n",
    "        out = self.network.predict(x).reshape(-1, 1)\n",
    "        return out\n",
    "\n",
    "    def postprocess(self, model_out: np.ndarray, **kwargs) -> np.ndarray:\n",
    "        # Define the range of the model outputs\n",
    "        min_value = 3\n",
    "        max_value = 8\n",
    "\n",
    "        # Number of possible output classes\n",
    "        num_classes = max_value - min_value + 1\n",
    "\n",
    "        # Flatten the model outputs to handle them\n",
    "        model_out = model_out.flatten()\n",
    "\n",
    "        # Ensure all model outputs are within the specified range\n",
    "        if np.any(model_out < min_value) or np.any(model_out > max_value):\n",
    "            raise ValueError(\"One or more model outputs are out of the expected range (3 to 8).\")\n",
    "\n",
    "        # Initialize the one-hot encoded array\n",
    "        one_hot_batch = np.zeros((model_out.shape[0], num_classes), dtype=int)\n",
    "\n",
    "        # Convert each model output to its corresponding one-hot encoded vector\n",
    "        for i, output in enumerate(model_out):\n",
    "            one_hot_batch[i, output - min_value] = 1\n",
    "\n",
    "        return one_hot_batch\n",
    "\n",
    "    def output_formatter(\n",
    "        self,\n",
    "        model_out: Any,\n",
    "        tables: Sequence[AiTable],\n",
    "        dataframes: Sequence[pd.DataFrame],\n",
    "        meta: Dict[str, Any],\n",
    "        categories: Optional[Sequence[Dict[str, Any]]] = None,\n",
    "        **kwargs\n",
    "    ) -> AiCOCOTabularOutputDataModel:\n",
    "\n",
    "        output = self.formatter(\n",
    "                    model_out=model_out,\n",
    "                    tables=tables,\n",
    "                    dataframes=dataframes,\n",
    "                    categories=categories,\n",
    "                    meta=meta,\n",
    "                )\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is only for jupyter notebook. You don\"t need this in stand-alone script.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = InferAPP(\n",
    "    infer_function=ClassificationInferenceModel(),\n",
    "    input_data_model=AiCOCOTabularInputDataModel,\n",
    "    output_data_model=AiCOCOTabularOutputDataModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "app.run(port=int(os.getenv(\"PORT\", 9111)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send request\n",
    "We can send request to the running server by `send_request.py` which opens the input files and the corresponding JSON file and would be sent via formdata. We expect to have response in AiCOCO tabular format.\n",
    "\n",
    "```bash\n",
    "# pwd: examples/inference\n",
    "python send_request.py -f test_data/tabular/cls/test_cls.csv -d test_data/tabular/cls/input.json\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dockerfile\n",
    "In order to interact with other services, we have to wrap the inference model into a docker container. \n",
    "Here\"s an example of the dockerfile. Please put your python dependencies into `requirements.txt` first."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```dockerfile\n",
    "FROM python:3.9-slim\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "RUN pip install https://github.com/ailabstw/FLaVor/archive/refs/heads/release/stable.zip\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY your_script.py  /app/\n",
    "\n",
    "CMD [\"python\", \"your_script.py\"]\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
