{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular regression task with FLaVor inference service"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This guide will walk you through tailoring the FLaVor inference service for tabular regression tasks using pytorch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the working environment, please ensure you have the following dependencies installed:\n",
    "\n",
    "```\n",
    "python >= 3.9\n",
    "torch >= 2.1.0\n",
    "```\n",
    "\n",
    "or simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry install --with tabular_reg_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from flavor.serve.apps import InferAPP\n",
    "from flavor.serve.inference.data_models.api import (\n",
    "    BaseAiCOCOTabularInputDataModel,\n",
    "    BaseAiCOCOTabularOutputDataModel,\n",
    ")\n",
    "from flavor.serve.inference.data_models.functional import AiTable\n",
    "from flavor.serve.inference.inference_models import BaseAiCOCOTabularInferenceModel\n",
    "from flavor.serve.inference.strategies import AiCOCOTabularRegressionOutputStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRegressor(nn.Module):\n",
    "    def __init__(self, input_dim: int = 10, hidden_dim: int = 32, output_dim: int = 1):\n",
    "        super(SimpleRegressor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionInferenceModel(BaseAiCOCOTabularInferenceModel):\n",
    "    def __init__(self):\n",
    "        self.formatter = AiCOCOTabularRegressionOutputStrategy()\n",
    "        super().__init__()\n",
    "\n",
    "    def define_inference_network(self) -> Callable:\n",
    "        input_dim = 8  # change this if needed\n",
    "        model = SimpleRegressor(input_dim=input_dim, hidden_dim=32, output_dim=1)\n",
    "        model.eval()  # Set the model to evaluation mode.\n",
    "        return model\n",
    "\n",
    "    def set_categories(self) -> List[Dict[str, Any]]:\n",
    "        return None\n",
    "\n",
    "    def set_regressions(self) -> None:\n",
    "        regressions = [\n",
    "            {\"name\": \"reg_value\"}\n",
    "        ]\n",
    "        return regressions\n",
    "\n",
    "    def data_reader(self, files: Sequence[str], **kwargs) -> List[pd.DataFrame]:\n",
    "        file_names = sorted(files, key=lambda s: s[::-1])\n",
    "        dataframes = [pd.read_csv(file) for file in file_names]\n",
    "        return dataframes\n",
    "\n",
    "    def preprocess(self, data: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "        return pd.concat(data)\n",
    "\n",
    "    def inference(self, x: pd.DataFrame):\n",
    "        with torch.no_grad():\n",
    "            input_tensor = torch.tensor(x.values.astype(np.float32))\n",
    "            output_tensor = self.network(input_tensor)\n",
    "            out = output_tensor.numpy().reshape(-1, 1)\n",
    "        return out\n",
    "\n",
    "    def postprocess(self, model_out: np.ndarray, **kwargs) -> np.ndarray:\n",
    "        return model_out\n",
    "\n",
    "    def output_formatter(\n",
    "        self,\n",
    "        model_out: Any,\n",
    "        tables: Sequence[AiTable],\n",
    "        dataframes: Sequence[pd.DataFrame],\n",
    "        meta: Dict[str, Any],\n",
    "        regressions: Optional[Sequence[Dict[str, Any]]] = None,\n",
    "        **kwargs,\n",
    "    ) -> BaseAiCOCOTabularOutputDataModel:\n",
    "\n",
    "        output = self.formatter(\n",
    "            model_out=model_out,\n",
    "            tables=tables,\n",
    "            dataframes=dataframes,\n",
    "            regressions=regressions,\n",
    "            meta=meta,\n",
    "        )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is only for jupyter notebook. You don\"t need this in stand-alone script.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = InferAPP(\n",
    "    infer_function=RegressionInferenceModel(),\n",
    "    input_data_model=BaseAiCOCOTabularInputDataModel,\n",
    "    output_data_model=BaseAiCOCOTabularOutputDataModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run(port=int(os.getenv(\"PORT\", 9111)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send request\n",
    "We can send request to the running server by `send_request.py` which opens the input files and the corresponding JSON file and would be sent via formdata. We expect to have response in AiCOCO tabular format.\n",
    "\n",
    "```bash\n",
    "# pwd: examples/inference\n",
    "python send_request.py -f test_data/tabular/reg/test_reg.csv -d test_data/tabular/reg/input.json\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dockerfile\n",
    "In order to interact with other services, we have to wrap the inference model into a docker container. \n",
    "Here\"s an example of the dockerfile. Please put your python dependencies into `requirements.txt` first."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```dockerfile\n",
    "FROM python:3.9-slim\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "RUN pip install https://github.com/ailabstw/FLaVor/archive/refs/heads/release/stable.zip\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY your_script.py  /app/\n",
    "\n",
    "CMD [\"python\", \"your_script.py\"]\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
