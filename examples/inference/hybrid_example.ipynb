{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Callable, Dict, List, Sequence, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "from flavor.serve.apps import InferAPP\n",
    "from flavor.serve.inference.data_models.api import (\n",
    "    BaseAiCOCOImageInputDataModel,\n",
    "    BaseAiCOCOImageOutputDataModel,\n",
    ")\n",
    "from flavor.serve.inference.data_models.functional import AiImage\n",
    "from flavor.serve.inference.inference_models import BaseAiCOCOHybridInferenceModel\n",
    "from flavor.serve.inference.strategies import AiCOCOClassificationOutputStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridNet(nn.Module):\n",
    "    def __init__(self, csv_input_dim, image_feature_dim, fusion_hidden_dim=128):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_input_dim (int): csv dimension\n",
    "            image_feature_dim (int): image feature dimension\n",
    "            fusion_hidden_dim (int): fusion hidden dimension\n",
    "        \"\"\"\n",
    "        super(HybridNet, self).__init__()\n",
    "        \n",
    "        # image branch\n",
    "        self.image_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        self.image_fc = nn.Linear(64, image_feature_dim)\n",
    "        \n",
    "        # tabular branch\n",
    "        self.csv_fc = nn.Linear(csv_input_dim, image_feature_dim)\n",
    "        \n",
    "        # fusion branch\n",
    "        self.fusion_fc = nn.Linear(2 * image_feature_dim, fusion_hidden_dim)\n",
    "        \n",
    "        # classifier\n",
    "        self.out = nn.Linear(fusion_hidden_dim, 2)\n",
    "        \n",
    "    def forward(self, tensor_image, tensor_tabular):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor_image (tensor)\n",
    "            tensor_tabular (tensor)\n",
    "        Returns:\n",
    "            logits (tensor)\n",
    "        \"\"\"\n",
    "        # image forward\n",
    "        x_img = self.image_conv(tensor_image)         # shape: (batch_size, 64, 1, 1)\n",
    "        x_img = x_img.view(x_img.size(0), -1)    # shape: (batch_size, 64)\n",
    "        x_img = self.image_fc(x_img)             # shape: (batch_size, image_feature_dim)\n",
    "        \n",
    "        # tabular forward\n",
    "        x_csv = self.csv_fc(tensor_tabular)          # shape: (batch_size, image_feature_dim)\n",
    "        \n",
    "        # fusion\n",
    "        x = torch.cat((x_img, x_csv), dim=1)     # shape: (batch_size, 2 * image_feature_dim)\n",
    "        x = F.relu(self.fusion_fc(x))\n",
    "        logits = self.out(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationInferenceModel(BaseAiCOCOHybridInferenceModel):\n",
    "    def __init__(self):\n",
    "        self.formatter = AiCOCOClassificationOutputStrategy()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        super().__init__()\n",
    "\n",
    "    def define_inference_network(self) -> Callable:\n",
    "        network = HybridNet(csv_input_dim=22, image_feature_dim=32)\n",
    "        network.eval()\n",
    "        network.to(self.device)\n",
    "        return network\n",
    "\n",
    "    def set_categories(self) -> List[Dict[str, Any]]:\n",
    "        categories = [{\"name\": str(i)} for i in range(2)]\n",
    "        return categories\n",
    "\n",
    "    def set_regressions(self) -> None:\n",
    "        return None\n",
    "\n",
    "    def data_reader(self, image_files: Sequence[str], table_files: Sequence[str]):\n",
    "        image = Image.open(image_files[0])\n",
    "        tabular = pd.read_csv(table_files[0])\n",
    "        return image, tabular\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        image_data, table_data = x\n",
    "        # image data\n",
    "        img = np.array(image_data).transpose(2, 0, 1).astype(np.float32)\n",
    "        tensor_image = torch.tensor(img).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # csv data\n",
    "        tabular = table_data\n",
    "        tensor_tabular = torch.tensor(tabular.values.astype(np.float32)).to(self.device)\n",
    "        \n",
    "        return tensor_image, tensor_tabular\n",
    "\n",
    "    def inference(self, x) -> torch.Tensor:\n",
    "        tensor_image, tensor_tabular = x\n",
    "        with torch.no_grad():\n",
    "            out = self.network(tensor_image, tensor_tabular)\n",
    "        return out\n",
    "\n",
    "    def postprocess(self, model_out: torch.Tensor, **kwargs) -> np.ndarray:\n",
    "        model_out = model_out.squeeze(0).cpu().detach()\n",
    "        model_out = (nn.functional.softmax(model_out, dim=0) > 0.4).long()\n",
    "        return model_out.numpy()\n",
    "\n",
    "    def output_formatter(\n",
    "        self,\n",
    "        model_out: np.ndarray,\n",
    "        images: Sequence[AiImage],\n",
    "        categories: Sequence[Dict[str, Any]],\n",
    "        **kwargs\n",
    "    ) -> BaseAiCOCOImageOutputDataModel:\n",
    "\n",
    "        output = self.formatter(model_out=model_out, images=images, categories=categories)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is only for jupyter notebook. You don't need this in stand-alone script.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = InferAPP(\n",
    "    infer_function=ClassificationInferenceModel(),\n",
    "    input_data_model=BaseAiCOCOImageInputDataModel,\n",
    "    output_data_model=BaseAiCOCOImageOutputDataModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run(port=int(os.getenv(\"PORT\", 9111)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send request\n",
    "We can send request to the running server by `send_request.py` which opens the input files and the corresponding JSON file and would be sent via formdata. We expect to have response in AiCOCO format.\n",
    "\n",
    "```bash\n",
    "# pwd: examples/inference\n",
    "python send_request.py -f test_data/hybrid/451c164d-7684-44b1-81b2-956247db765b_20160112_102927.jpg -f test_data/hybrid/test_cls.csv -d test_data/hybrid/input.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dockerfile\n",
    "In order to interact with other services, we have to wrap the inference model into a docker container. Here's an example of the dockerfile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```dockerfile\n",
    "FROM nvidia/cuda:12.2.2-runtime-ubuntu20.04\n",
    "\n",
    "RUN apt-get update \\\n",
    "    && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\n",
    "        python3\\\n",
    "        python3-pip \\\n",
    "    && ln -sf /usr/bin/python3 /usr/bin/python\n",
    "\n",
    "RUN pip install torch==2.1.0+cu121 --extra-index-url https://download.pytorch.org/whl/cu121 --default-timeout=1000\n",
    "RUN pip install https://github.com/ailabstw/FLaVor/archive/refs/heads/release/stable.zip\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY your_script.py  /app/\n",
    "\n",
    "CMD [\"python\", \"your_script.py\"]\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
