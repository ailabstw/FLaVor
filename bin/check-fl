#!/usr/bin/env python
import argparse
import json
import multiprocessing as mp
import os
import subprocess
import sys

import numpy as np
from jsonschema import validate

from flavor.cook.utils import (
    CleanAllEvent,
    CleanInfoJson,
    IsSetEvent,
    SetEvent,
    WaitEvent,
)

os.environ["PYTHONWARNINGS"] = "ignore"

input_path_default = os.getenv("INPUT_PATH", "/data")
output_path_default = os.getenv("OUTPUT_PATH", "/output")
local_path_default = os.getenv("LOCAL_MODEL_PATH", "/weight/local.ckpt")
global_path_default = os.getenv("GLOBAL_MODEL_PATH", "/weight/global.ckpt")
log_path_default = os.getenv("LOG_PATH", "/log")

input_path = input(
    "Set $INPUT_PATH: (Press ENTER if using default env - {})".format(input_path_default)
)
os.environ["INPUT_PATH"] = input_path if input_path else input_path_default
output_path = input(
    "Set $OUTPUT_PATH: (Press ENTER if using default env - {})".format(output_path_default)
)
os.environ["OUTPUT_PATH"] = output_path if output_path else output_path_default
local_path = input(
    "Set $LOCAL_MODEL_PATH: (Press ENTER if using default env - {})".format(local_path_default)
)
os.environ["LOCAL_MODEL_PATH"] = local_path if local_path else local_path_default
global_path = input(
    "Set $GLOBAL_MODEL_PATH: (Press ENTER if using default env - {})".format(global_path_default)
)
os.environ["GLOBAL_MODEL_PATH"] = global_path if global_path else global_path_default
log_path = input("Set $LOG_PATH: (Press ENTER if using default env - {})".format(log_path_default))
os.environ["LOG_PATH"] = log_path if log_path else log_path_default


def logging_subprocess(process):
    _, stderr = process.communicate()
    if stderr:
        print(stderr)
        SetEvent("Error")
        SetEvent("TrainInitDone")
        SetEvent("TrainFinished")


def transfer_data_to_tensor(batch, map_location="cuda"):

    if isinstance(batch, np.ndarray):
        batch = batch

    if callable(getattr(batch, "to", None)):
        return batch.to(map_location)

    # when list
    if isinstance(batch, list):
        for i, x in enumerate(batch):
            batch[i] = transfer_data_to_tensor(x, map_location)
        return batch

    # when tuple
    if isinstance(batch, tuple):
        batch = list(batch)
        for i, x in enumerate(batch):
            batch[i] = transfer_data_to_tensor(x, map_location)
        return tuple(batch)

    # when dict
    if isinstance(batch, dict):
        for k, v in batch.items():
            batch[k] = transfer_data_to_tensor(v, map_location)

        return batch

    return batch


def load_checkpoint(path, map_location="cuda"):
    try:
        import torch

        return torch.load(path, map_location=map_location)
    except RuntimeError:
        import pickle

        with open(path, "rb") as f:
            ckpt = pickle.load(f)
        return transfer_data_to_tensor(ckpt, map_location=map_location)


def main():

    parser = argparse.ArgumentParser()
    parser.add_argument("-m", "--main", type=str, required=True, help="main process command")
    parser.add_argument(
        "-p", "--preprocess", type=str, help="data preprocess command", default=None
    )
    parser.add_argument(
        "--ignore-ckpt",
        action="store_true",
        help="ignore ckpt check for 3rd party aggregator",
        default=False,
    )
    args, unparsed = parser.parse_known_args()

    os.makedirs(os.environ["LOG_PATH"], exist_ok=True)
    os.makedirs(os.environ["OUTPUT_PATH"], exist_ok=True)

    CleanAllEvent()
    CleanInfoJson()
    if os.path.exists(os.environ["LOCAL_MODEL_PATH"]):
        os.remove(os.environ["LOCAL_MODEL_PATH"])
    os.makedirs(os.path.dirname(os.environ["LOCAL_MODEL_PATH"]), exist_ok=True)

    if args.preprocess:
        print("Start data process.")
        try:
            subprocess.check_output(
                [ele for ele in args.preprocess.split(" ") if ele.strip()],
                stderr=subprocess.STDOUT,
            )
        except subprocess.CalledProcessError as e:
            raise Exception(e.output.decode("utf-8"))

    print("Start training process.")
    trainingProcess = subprocess.Popen(
        [ele for ele in args.main.split(" ") if ele.strip()],
        stderr=subprocess.PIPE,
        universal_newlines=True,
    )
    monitorProcess = mp.Process(target=logging_subprocess, kwargs={"process": trainingProcess})
    monitorProcess.start()

    if not IsSetEvent("Error"):
        print("Wait TrainInitDone.")
    WaitEvent("TrainInitDone")

    if not IsSetEvent("Error"):
        print("Set TrainStarted.")
    SetEvent("TrainStarted")

    if not IsSetEvent("Error"):
        print("Wait TrainFinished.")
    WaitEvent("TrainFinished")

    trainingProcess.terminate()
    trainingProcess.kill()

    monitorProcess.terminate()
    monitorProcess.join()
    monitorProcess.close()

    if IsSetEvent("Error"):
        sys.exit()

    if IsSetEvent("TrainStarted"):
        raise AssertionError("TrainStarted event should be cleared")

    if not args.ignore_ckpt:
        print("Check Checkpoint")
        ckpt = load_checkpoint(os.environ["LOCAL_MODEL_PATH"])
        if "state_dict" not in ckpt:
            raise KeyError("state_dict not in checkpoint")
    else:
        print("Skip Checkpoint Checking")

    print("Validate info json")
    with open(
        os.path.join(os.path.dirname(os.environ["LOCAL_MODEL_PATH"]), "info.json"), "r"
    ) as openfile:
        instance = json.load(openfile)

    with open(
        os.path.join(os.path.dirname(os.path.realpath(__file__)), "../schema/FLresult.json"), "r"
    ) as openfile:
        schema = json.load(openfile)

    try:
        validate(instance=instance, schema=schema)
    except Exception:
        raise Exception("Json Schema Error")

    CleanInfoJson()
    if os.path.exists(os.environ["LOCAL_MODEL_PATH"]):
        os.remove(os.environ["LOCAL_MODEL_PATH"])

    print("Run Successfullly !!!")


if __name__ == "__main__":

    main()
